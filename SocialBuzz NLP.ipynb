{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22b6ef9",
   "metadata": {},
   "source": [
    "# __NLP on the SocialBuzz Sentiment Analysis Dataset from Kaggle__\n",
    "\n",
    "#### The purpose of this notebook is to classify social media posts as positive or negative.\n",
    "\n",
    "_Kelby Mace 2/7/2026_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "285afc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import spacy\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"eshummalik/socialbuzz-sentiment-analytics\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2f183",
   "metadata": {},
   "source": [
    "## __Data Preprocessing & Feature Engineering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e52ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª          ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                                Text    Sentiment  \\\n",
       "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
       "1   Traffic was terrible this morning.           ...   Negative     \n",
       "2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
       "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
       "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
       "\n",
       "            Timestamp            User     Platform  \\\n",
       "0 2023-01-15 12:30:00   User123          Twitter     \n",
       "1 2023-01-15 08:45:00   CommuterX        Twitter     \n",
       "2 2023-01-15 15:45:00   FitnessFan      Instagram    \n",
       "3 2023-01-15 18:20:00   AdventureX       Facebook    \n",
       "4 2023-01-15 19:55:00   ChefCook        Instagram    \n",
       "\n",
       "                                     Hashtags  Retweets  Likes       Country  \\\n",
       "0   #Nature #Park                                    15     30     USA         \n",
       "1   #Traffic #Morning                                 5     10     Canada      \n",
       "2   #Fitness #Workout                                20     40   USA           \n",
       "3   #Travel #Adventure                                8     15     UK          \n",
       "4   #Cooking #Food                                   12     25    Australia    \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sentimentdataset.csv\")\n",
    "\n",
    "# Fix data tytpes\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df['Likes'] = df['Likes'].astype(int)\n",
    "df['Retweets'] = df['Retweets'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362a907b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Text Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enjoying a beautiful day at the park</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traffic was terrible this morning</td>\n",
       "      <td>negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just finished an amazing workout</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excited about the upcoming weekend getaway</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trying out a new recipe for dinner tonight</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text Sentiment           Timestamp  \\\n",
       "0        enjoying a beautiful day at the park  positive 2023-01-15 12:30:00   \n",
       "1           traffic was terrible this morning  negative 2023-01-15 08:45:00   \n",
       "2           just finished an amazing workout   positive 2023-01-15 15:45:00   \n",
       "3  excited about the upcoming weekend getaway  positive 2023-01-15 18:20:00   \n",
       "4  trying out a new recipe for dinner tonight   neutral 2023-01-15 19:55:00   \n",
       "\n",
       "             User     Platform                                    Hashtags  \\\n",
       "0   User123          Twitter     #Nature #Park                               \n",
       "1   CommuterX        Twitter     #Traffic #Morning                           \n",
       "2   FitnessFan      Instagram    #Fitness #Workout                           \n",
       "3   AdventureX       Facebook    #Travel #Adventure                          \n",
       "4   ChefCook        Instagram    #Cooking #Food                              \n",
       "\n",
       "   Retweets  Likes       Country  Year  Month  Day  Hour  Text Length  \n",
       "0        15     30     USA        2023      1   15    12           36  \n",
       "1         5     10     Canada     2023      1   15     8           33  \n",
       "2        20     40   USA          2023      1   15    15           33  \n",
       "3         8     15     UK         2023      1   15    18           42  \n",
       "4        12     25    Australia   2023      1   15    19           42  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean text\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Lowercase, strip whitespace, remove punctuation, and replace numbers with <NUM>.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    text = re.sub(r'[0-9]', '<NUM>', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply text cleaning function\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: x.strip().lower())\n",
    "\n",
    "#Add text length feature\n",
    "df['Text Length'] = df['Text'].apply(len)\n",
    "\n",
    "# Drop extra index columns\n",
    "if 'Unnamed: 0.1' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 0.1'])\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb38ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive          45\n",
       "joy               44\n",
       "excitement        37\n",
       "contentment       19\n",
       "neutral           18\n",
       "                  ..\n",
       "lostlove           1\n",
       "emotionalstorm     1\n",
       "suffering          1\n",
       "bittersweet        1\n",
       "intrigue           1\n",
       "Name: count, Length: 191, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So many sentiment categories! Going to have to reduce them\n",
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4021414",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comment out after initial run - save off csv with cleaned text and new feature\n",
    "\n",
    "## Use a pre-trained zero-shot classifier from Hugging Face to map sentiment categories to positive, neutral, or negative\n",
    "# candidate = [\"positive\", \"neutral\", \"negative\"]\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# def map_label(label: str):\n",
    "#     out = classifier(label, candidate_labels=candidate, multi_label=False)\n",
    "#     return out[\"labels\"][0], out[\"scores\"][0]  # predicted class + confidence\n",
    "\n",
    "# # Example\n",
    "# map_label(\"furious\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eae86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See how zero-shot classification does on the actual text\n",
    "## This takes a really long time so I only did it once\n",
    "\n",
    "# df['Predicted Sentiment'] = df['Text'].apply(lambda x: map_label(x)[0])\n",
    "# df['Prediction Confidence'] = df['Text'].apply(lambda x: map_label(x)[1])\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8c177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted Sentiment\n",
       "positive    0.684426\n",
       "negative    0.278689\n",
       "neutral     0.036885\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hardly any neutral... that will make it really tough to train\n",
    "df['Predicted Sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cd3de5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "      <th>Prediction Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>contemplating lifes mysteries under the starry...</td>\n",
       "      <td>contemplation</td>\n",
       "      <td>2016-07-02 23:30:00</td>\n",
       "      <td>Stargazer</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Contemplation #StarryNight</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>UK</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.348642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text      Sentiment  \\\n",
       "349  contemplating lifes mysteries under the starry...  contemplation   \n",
       "\n",
       "              Timestamp               User    Platform  \\\n",
       "349 2016-07-02 23:30:00   Stargazer          Twitter     \n",
       "\n",
       "                                        Hashtags  Retweets  Likes  \\\n",
       "349   #Contemplation #StarryNight                       28     55   \n",
       "\n",
       "                 Country  Year  Month  Day  Hour  Text Length  \\\n",
       "349   UK                  2016      7    2    23           56   \n",
       "\n",
       "    Predicted Sentiment  Prediction Confidence  \n",
       "349            negative               0.348642  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Prediction Confidence'] == df['Prediction Confidence'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply zero-shot again to the actual sentiment rather than the text itself\n",
    "\n",
    "# df['Sentiment Reduced'], df['Sentiment Reduced Confidence'] = zip(*df['Sentiment'].apply(lambda x: map_label(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecdb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save as csv so I don't have to run the zero-shot classification again\n",
    "# df.to_csv(\"sentiment_with_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6746c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text Sentiment Match\n",
       " True     0.671642\n",
       " False    0.328358\n",
       " Name: proportion, dtype: float64,\n",
       " Sentiment Prediction Match\n",
       " True    1.0\n",
       " Name: proportion, dtype: float64,\n",
       " Predictions Match\n",
       " True     0.671642\n",
       " False    0.328358\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For sentiments already classified as positive, neutral, or negative, how often does the predicted sentiment match the original sentiment?\n",
    "\n",
    "df_three = df.copy()\n",
    "\n",
    "df_three = df_three.loc[df_three['Sentiment'].isin([\"positive\", \"neutral\", \"negative\"])]\n",
    "df_three['Text Sentiment Match'] = df_three.apply(lambda row: row['Sentiment'] == row['Predicted Sentiment'], axis=1)\n",
    "\n",
    "# This works 100% of the time -- good gut check\n",
    "df_three['Sentiment Prediction Match'] = df_three.apply(lambda row: row['Sentiment'] == row['Sentiment Reduced'], axis=1)\n",
    "\n",
    "df_three['Predictions Match'] = df_three.apply(lambda row: row['Text Sentiment Match'] == row['Sentiment Prediction Match'], axis=1)\n",
    "\n",
    "df_three['Text Sentiment Match'].value_counts(normalize=True), df_three['Sentiment Prediction Match'].value_counts(normalize=True), df_three['Predictions Match'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0738626b",
   "metadata": {},
   "source": [
    "### __Load in CSV After Zero Shot Classification__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a558d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>Text Predicted Sentiment</th>\n",
       "      <th>Text Prediction Confidence</th>\n",
       "      <th>Sentiment Predicted Sentiment</th>\n",
       "      <th>Sentiment Prediction Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enjoying a beautiful day at the park</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.936028</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traffic was terrible this morning</td>\n",
       "      <td>negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.988335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just finished an amazing workout</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.923207</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excited about the upcoming weekend getaway</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.975727</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trying out a new recipe for dinner tonight</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.662256</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.855826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text Sentiment            Timestamp  \\\n",
       "0        enjoying a beautiful day at the park  positive  2023-01-15 12:30:00   \n",
       "1           traffic was terrible this morning  negative  2023-01-15 08:45:00   \n",
       "2            just finished an amazing workout  positive  2023-01-15 15:45:00   \n",
       "3  excited about the upcoming weekend getaway  positive  2023-01-15 18:20:00   \n",
       "4  trying out a new recipe for dinner tonight   neutral  2023-01-15 19:55:00   \n",
       "\n",
       "             User     Platform                                    Hashtags  \\\n",
       "0   User123          Twitter     #Nature #Park                               \n",
       "1   CommuterX        Twitter     #Traffic #Morning                           \n",
       "2   FitnessFan      Instagram    #Fitness #Workout                           \n",
       "3   AdventureX       Facebook    #Travel #Adventure                          \n",
       "4   ChefCook        Instagram    #Cooking #Food                              \n",
       "\n",
       "   Retweets  Likes       Country  Year  Month  Day  Hour  Text Length  \\\n",
       "0        15     30     USA        2023      1   15    12           36   \n",
       "1         5     10     Canada     2023      1   15     8           33   \n",
       "2        20     40   USA          2023      1   15    15           32   \n",
       "3         8     15     UK         2023      1   15    18           42   \n",
       "4        12     25    Australia   2023      1   15    19           42   \n",
       "\n",
       "  Text Predicted Sentiment  Text Prediction Confidence  \\\n",
       "0                 positive                    0.936028   \n",
       "1                 negative                    0.976853   \n",
       "2                 positive                    0.923207   \n",
       "3                 positive                    0.975727   \n",
       "4                 positive                    0.662256   \n",
       "\n",
       "  Sentiment Predicted Sentiment  Sentiment Prediction Confidence  \n",
       "0                      positive                         0.987529  \n",
       "1                      negative                         0.988335  \n",
       "2                      positive                         0.987529  \n",
       "3                      positive                         0.987529  \n",
       "4                       neutral                         0.855826  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sentiment_with_predictions.csv\")\n",
    "\n",
    "# Rename columns so they aren't so confusing\n",
    "df = df.rename(columns={\n",
    "    \"Predicted Sentiment\": \"Text Predicted Sentiment\",\n",
    "    \"Prediction Confidence\": \"Text Prediction Confidence\",\n",
    "    \"Sentiment Reduced\": \"Sentiment Predicted Sentiment\",\n",
    "    \"Sentiment Reduced Confidence\": \"Sentiment Prediction Confidence\"\n",
    "    })\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "241b6a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>Text Predicted Sentiment</th>\n",
       "      <th>Text Prediction Confidence</th>\n",
       "      <th>Sentiment Predicted Sentiment</th>\n",
       "      <th>Sentiment Prediction Confidence</th>\n",
       "      <th>Num Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enjoying a beautiful day at the park</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>twitter</td>\n",
       "      <td>nature park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.936028</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traffic was terrible this morning</td>\n",
       "      <td>negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>twitter</td>\n",
       "      <td>traffic morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.988335</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just finished an amazing workout</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>instagram</td>\n",
       "      <td>fitness workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.923207</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excited about the upcoming weekend getaway</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>facebook</td>\n",
       "      <td>travel adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.975727</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trying out a new recipe for dinner tonight</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>instagram</td>\n",
       "      <td>cooking food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.662256</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.855826</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text Sentiment            Timestamp  \\\n",
       "0        enjoying a beautiful day at the park  positive  2023-01-15 12:30:00   \n",
       "1           traffic was terrible this morning  negative  2023-01-15 08:45:00   \n",
       "2            just finished an amazing workout  positive  2023-01-15 15:45:00   \n",
       "3  excited about the upcoming weekend getaway  positive  2023-01-15 18:20:00   \n",
       "4  trying out a new recipe for dinner tonight   neutral  2023-01-15 19:55:00   \n",
       "\n",
       "             User   Platform          Hashtags  Retweets  Likes       Country  \\\n",
       "0   User123          twitter       nature park        15     30     USA         \n",
       "1   CommuterX        twitter   traffic morning         5     10     Canada      \n",
       "2   FitnessFan     instagram   fitness workout        20     40   USA           \n",
       "3   AdventureX      facebook  travel adventure         8     15     UK          \n",
       "4   ChefCook       instagram      cooking food        12     25    Australia    \n",
       "\n",
       "   Year  Month  Day  Hour  Text Length Text Predicted Sentiment  \\\n",
       "0  2023      1   15    12           36                 positive   \n",
       "1  2023      1   15     8           33                 negative   \n",
       "2  2023      1   15    15           32                 positive   \n",
       "3  2023      1   15    18           42                 positive   \n",
       "4  2023      1   15    19           42                 positive   \n",
       "\n",
       "   Text Prediction Confidence Sentiment Predicted Sentiment  \\\n",
       "0                    0.936028                      positive   \n",
       "1                    0.976853                      negative   \n",
       "2                    0.923207                      positive   \n",
       "3                    0.975727                      positive   \n",
       "4                    0.662256                       neutral   \n",
       "\n",
       "   Sentiment Prediction Confidence  Num Hashtags  \n",
       "0                         0.987529             2  \n",
       "1                         0.988335             2  \n",
       "2                         0.987529             2  \n",
       "3                         0.987529             2  \n",
       "4                         0.855826             2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the Hashtags and Platform columns which I overlooked previously\n",
    "df['Hashtags'] = df['Hashtags'].apply(lambda x: x.strip().lower())\n",
    "df['Hashtags'] = df['Hashtags'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "df['Platform'] = df['Platform'].apply(lambda x: x.strip().lower())\n",
    "\n",
    "# Create a new feature for the number of hashtags by counting the number of words in the cleaned Hashtags column\n",
    "df['Num Hashtags'] = df['Hashtags'].apply(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d2e04",
   "metadata": {},
   "source": [
    "### __Examine Zero Shot Performance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d0acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text Predicted Sentiment</th>\n",
       "      <th>Sentiment Predicted Sentiment</th>\n",
       "      <th>Text Prediction Confidence</th>\n",
       "      <th>Sentiment Prediction Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>yearning for a touch thats not there echoes of...</td>\n",
       "      <td>yearning</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.558199</td>\n",
       "      <td>0.393416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>yearning for the warmth of a vanished sun a he...</td>\n",
       "      <td>yearning</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.920840</td>\n",
       "      <td>0.393416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>reflecting on personal growth achieved through...</td>\n",
       "      <td>reflection</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.831560</td>\n",
       "      <td>0.445453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>exploring the universe within during a mindful...</td>\n",
       "      <td>innerjourney</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.537221</td>\n",
       "      <td>0.423696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>reflective contemplation amid the ruins of a f...</td>\n",
       "      <td>reflection</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.517170</td>\n",
       "      <td>0.445453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>standing before the grandeur of the eiffel tow...</td>\n",
       "      <td>reflection</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.738599</td>\n",
       "      <td>0.445453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>in the tranquility of kyotos bamboo forest whi...</td>\n",
       "      <td>tranquility</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.557854</td>\n",
       "      <td>0.499439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>at the front row of adeles concert each note o...</td>\n",
       "      <td>emotion</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.904690</td>\n",
       "      <td>0.382542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>immersed in the soulful melodies of adele tear...</td>\n",
       "      <td>emotion</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.380305</td>\n",
       "      <td>0.382542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>facing a defeat in the championship the boxer ...</td>\n",
       "      <td>reflection</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.768080</td>\n",
       "      <td>0.445453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>in the serene beauty of a sunset nature unfold...</td>\n",
       "      <td>tranquility</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.929172</td>\n",
       "      <td>0.499439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>in the realm of literature a captivating novel...</td>\n",
       "      <td>imagination</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.844612</td>\n",
       "      <td>0.426509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text     Sentiment  \\\n",
       "299  yearning for a touch thats not there echoes of...      yearning   \n",
       "321  yearning for the warmth of a vanished sun a he...      yearning   \n",
       "356  reflecting on personal growth achieved through...    reflection   \n",
       "393  exploring the universe within during a mindful...  innerjourney   \n",
       "397  reflective contemplation amid the ruins of a f...    reflection   \n",
       "490  standing before the grandeur of the eiffel tow...    reflection   \n",
       "508  in the tranquility of kyotos bamboo forest whi...   tranquility   \n",
       "510  at the front row of adeles concert each note o...       emotion   \n",
       "522  immersed in the soulful melodies of adele tear...       emotion   \n",
       "552  facing a defeat in the championship the boxer ...    reflection   \n",
       "560  in the serene beauty of a sunset nature unfold...   tranquility   \n",
       "568  in the realm of literature a captivating novel...   imagination   \n",
       "\n",
       "    Text Predicted Sentiment Sentiment Predicted Sentiment  \\\n",
       "299                 negative                      positive   \n",
       "321                 negative                      positive   \n",
       "356                 positive                      positive   \n",
       "393                 positive                      positive   \n",
       "397                  neutral                      positive   \n",
       "490                 positive                      positive   \n",
       "508                 positive                       neutral   \n",
       "510                 positive                      positive   \n",
       "522                 positive                      positive   \n",
       "552                 negative                      positive   \n",
       "560                 positive                       neutral   \n",
       "568                 positive                      positive   \n",
       "\n",
       "     Text Prediction Confidence  Sentiment Prediction Confidence  \n",
       "299                    0.558199                         0.393416  \n",
       "321                    0.920840                         0.393416  \n",
       "356                    0.831560                         0.445453  \n",
       "393                    0.537221                         0.423696  \n",
       "397                    0.517170                         0.445453  \n",
       "490                    0.738599                         0.445453  \n",
       "508                    0.557854                         0.499439  \n",
       "510                    0.904690                         0.382542  \n",
       "522                    0.380305                         0.382542  \n",
       "552                    0.768080                         0.445453  \n",
       "560                    0.929172                         0.499439  \n",
       "568                    0.844612                         0.426509  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = ['positive', 'neutral', 'negative']\n",
    "\n",
    "other_sentiments = df.loc[~df['Sentiment'].isin(sentiments)][['Text','Sentiment', 'Text Predicted Sentiment', 'Sentiment Predicted Sentiment', 'Text Prediction Confidence', 'Sentiment Prediction Confidence']]\n",
    "\n",
    "other_sentiments.loc[other_sentiments['Sentiment Prediction Confidence'] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69c6282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Final Sentiment\n",
       "positive    0.674863\n",
       "negative    0.285519\n",
       "neutral     0.039617\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the highest confidence level, unless both are below 0.5, in which case we will classify as neutral\n",
    "\n",
    "def final_sentiment(row):\n",
    "    if row['Sentiment Prediction Confidence'] >= row['Text Prediction Confidence'] and row['Sentiment Prediction Confidence']  >= 0.5:\n",
    "        return row['Sentiment Predicted Sentiment']\n",
    "    elif row['Text Prediction Confidence'] >= row['Sentiment Prediction Confidence'] and row['Text Prediction Confidence'] >= 0.5:\n",
    "        return row['Text Predicted Sentiment']\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['Final Sentiment'] = df.apply(final_sentiment, axis=1)\n",
    "df['Final Sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e013c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove neutrals because they are too small of a category to train on\n",
    "# Trying to do unsupervised learning, not zero-shot to logistic regression comparison\n",
    "# Take neutrals out for now\n",
    "df = df.loc[df['Final Sentiment'] != 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572fbcba",
   "metadata": {},
   "source": [
    "### __Define Target and Features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc0ef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text features: ['Text', 'Hashtags']\n",
      "Numeric features: ['Retweets', 'Likes', 'Year', 'Month', 'Day', 'Hour', 'Text Length', 'Num Hashtags']\n",
      "Categorical features: ['Platform', 'Country']\n"
     ]
    }
   ],
   "source": [
    "target_col = \"Final Sentiment\" # column to classify\n",
    "text_col = \"Text\"\n",
    "\n",
    "# remove columns I don't want as predictors\n",
    "drop_cols = [\n",
    "    target_col,\n",
    "    \"Sentiment\",\n",
    "    \"Text Predicted Sentiment\",\n",
    "    \"Sentiment Predicted Sentiment\",\n",
    "    \"Text Prediction Confidence\",\n",
    "    \"Sentiment Prediction Confidence\",\n",
    "    \"Timestamp\",\n",
    "    \"User\"\n",
    "]\n",
    "\n",
    "df_model = df.copy()\n",
    "df_model = df_model.dropna(subset=[target_col, text_col])\n",
    "\n",
    "X = df_model.drop(columns=[c for c in drop_cols if c in df_model.columns], errors=\"ignore\")\n",
    "y = df_model[target_col]\n",
    "\n",
    "# Auto-detect other feature types (excluding text)\n",
    "text_features = [\"Text\", \"Hashtags\"]\n",
    "numeric_features = [c for c in X.select_dtypes(include=[np.number]).columns if c not in text_features]\n",
    "categorical_features = [c for c in X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns if c not in text_features]\n",
    "\n",
    "print(\"Text features:\", text_features)\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de380c0f",
   "metadata": {},
   "source": [
    "## __Logistic Regression__\n",
    "\n",
    "_Experiment 1: Stop word removal, but no stemming or lemmatization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98047936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: No stemming/lemmatization, stop word removal\n",
    "\n",
    "# A few words like \"not\" are important for sentiment, so remove them from the stopword list\n",
    "custom_stopwords = set(text.ENGLISH_STOP_WORDS) - {\"not\", \"no\", \"never\"}\n",
    "custom_stopwords = sorted(list(custom_stopwords))  # convert set -> list\n",
    "\n",
    "text_transformer = TfidfVectorizer(\n",
    "    stop_words=custom_stopwords,   # custom stopword list with negative words retained\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "hashtags_transformer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False))  # works with sparse output\n",
    "])\n",
    "\n",
    "# Use one-hot encoding for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", text_transformer, \"Text\"),\n",
    "        (\"hashtags\", hashtags_transformer, \"Hashtags\"),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "888749f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['negative' 'positive']\n",
      "coef shape: (1, 1373)\n",
      "\n",
      "Top features pushing toward class 'positive'\n",
      "                     feature      coef\n",
      "0         hashtags__serenity  1.090554\n",
      "1    hashtags__determination  1.011062\n",
      "2        hashtags__curiosity  0.986004\n",
      "3                  text__new  0.952790\n",
      "4        hashtags__nostalgia  0.898096\n",
      "5    cat__Country_ UK         0.835851\n",
      "6    cat__Country_ USA        0.790221\n",
      "7        hashtags__gratitude  0.737335\n",
      "8         hashtags__euphoria  0.705147\n",
      "9       hashtags__acceptance  0.689559\n",
      "10          cat__Country_USA  0.685512\n",
      "11        hashtags__inspired  0.652107\n",
      "12             hashtags__awe  0.646460\n",
      "13     hashtags__inspiration  0.622132\n",
      "14  cat__Country_ Canada      0.621223\n",
      "15                 text__joy  0.606809\n",
      "16              text__beauty  0.603381\n",
      "17     hashtags__contentment  0.600472\n",
      "18             text__friends  0.572271\n",
      "19           hashtags__pride  0.561122\n",
      "\n",
      "Top features pushing toward class 'negative'\n",
      "                      feature      coef\n",
      "0           hashtags__despair -1.541607\n",
      "1             hashtags__grief -1.525442\n",
      "2        hashtags__loneliness -1.367666\n",
      "3            hashtags__regret -1.276275\n",
      "4         hashtags__confusion -1.252341\n",
      "5   cat__Country_ India       -1.234522\n",
      "6           hashtags__arousal -1.208062\n",
      "7          hashtags__betrayal -1.144584\n",
      "8        hashtags__desolation -1.139955\n",
      "9        hashtags__melancholy -1.137826\n",
      "10  cat__Country_ Canada      -1.122235\n",
      "11               text__echoes -1.093173\n",
      "12   hashtags__disappointment -1.025449\n",
      "13       hashtags__bitterness -1.017224\n",
      "14      hashtags__frustration -0.986278\n",
      "15      hashtags__overwhelmed -0.977267\n",
      "16          text__frustration -0.932544\n",
      "17             hashtags__fear -0.914442\n",
      "18             text__solitude -0.897320\n",
      "19                  text__bad -0.883163\n"
     ]
    }
   ],
   "source": [
    "# Create model pipeline\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Fit model to training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Look at feature importances\n",
    "model = clf.named_steps[\"model\"]\n",
    "pre = clf.named_steps[\"preprocessor\"]\n",
    "\n",
    "feature_names = pre.get_feature_names_out()\n",
    "classes = model.classes_\n",
    "coefs = model.coef_\n",
    "\n",
    "print(\"classes:\", classes)\n",
    "print(\"coef shape:\", coefs.shape)\n",
    "\n",
    "top_k = 20\n",
    "\n",
    "if coefs.shape[0] == 1:\n",
    "    # Binary case: coefficients are for classes[1] vs classes[0]\n",
    "    pos_class = classes[1]\n",
    "    neg_class = classes[0]\n",
    "    w = coefs[0]\n",
    "\n",
    "    top_pos = np.argsort(w)[-top_k:][::-1]\n",
    "    top_neg = np.argsort(w)[:top_k]\n",
    "\n",
    "    print(f\"\\nTop features pushing toward class '{pos_class}'\")\n",
    "    print(pd.DataFrame({\"feature\": feature_names[top_pos], \"coef\": w[top_pos]}))\n",
    "\n",
    "    print(f\"\\nTop features pushing toward class '{neg_class}'\")\n",
    "    print(pd.DataFrame({\"feature\": feature_names[top_neg], \"coef\": w[top_neg]}))\n",
    "else:\n",
    "    # Multiclass case\n",
    "    for i, cls in enumerate(classes):\n",
    "        idx = np.argsort(coefs[i])[-top_k:][::-1]\n",
    "        print(f\"\\nTop features for class = {cls}\")\n",
    "        print(pd.DataFrame({\"feature\": feature_names[idx], \"coef\": coefs[i, idx]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f58c597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.60      0.75        42\n",
      "    positive       0.85      1.00      0.92        99\n",
      "\n",
      "    accuracy                           0.88       141\n",
      "   macro avg       0.93      0.80      0.83       141\n",
      "weighted avg       0.90      0.88      0.87       141\n",
      "\n",
      "Confusion matrix:\n",
      " [[25 17]\n",
      " [ 0 99]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41fddcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Text Length</th>\n",
       "      <th>Text Predicted Sentiment</th>\n",
       "      <th>Text Prediction Confidence</th>\n",
       "      <th>Sentiment Predicted Sentiment</th>\n",
       "      <th>Sentiment Prediction Confidence</th>\n",
       "      <th>Num Hashtags</th>\n",
       "      <th>Final Sentiment</th>\n",
       "      <th>Text_lemma</th>\n",
       "      <th>Hashtags_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enjoying a beautiful day at the park</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>twitter</td>\n",
       "      <td>nature park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.936028</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>enjoy a beautiful day at the park</td>\n",
       "      <td>nature park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traffic was terrible this morning</td>\n",
       "      <td>negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>twitter</td>\n",
       "      <td>traffic morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.988335</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>traffic be terrible this morning</td>\n",
       "      <td>traffic morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just finished an amazing workout</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>instagram</td>\n",
       "      <td>fitness workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.923207</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>just finish an amazing workout</td>\n",
       "      <td>fitness workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excited about the upcoming weekend getaway</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>facebook</td>\n",
       "      <td>travel adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.975727</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>excited about the upcoming weekend getaway</td>\n",
       "      <td>travel adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feeling grateful for the little things in life</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-16 09:10:00</td>\n",
       "      <td>GratitudeNow</td>\n",
       "      <td>twitter</td>\n",
       "      <td>gratitude positivevibes</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>India</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.916279</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>feel grateful for the little thing in life</td>\n",
       "      <td>gratitude positivevibe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Text Sentiment  \\\n",
       "0            enjoying a beautiful day at the park  positive   \n",
       "1               traffic was terrible this morning  negative   \n",
       "2                just finished an amazing workout  positive   \n",
       "3      excited about the upcoming weekend getaway  positive   \n",
       "5  feeling grateful for the little things in life  positive   \n",
       "\n",
       "             Timestamp            User   Platform                 Hashtags  \\\n",
       "0  2023-01-15 12:30:00   User123          twitter              nature park   \n",
       "1  2023-01-15 08:45:00   CommuterX        twitter          traffic morning   \n",
       "2  2023-01-15 15:45:00   FitnessFan     instagram          fitness workout   \n",
       "3  2023-01-15 18:20:00   AdventureX      facebook         travel adventure   \n",
       "5  2023-01-16 09:10:00   GratitudeNow     twitter  gratitude positivevibes   \n",
       "\n",
       "   Retweets  Likes       Country  Year  ...  Hour  Text Length  \\\n",
       "0        15     30     USA        2023  ...    12           36   \n",
       "1         5     10     Canada     2023  ...     8           33   \n",
       "2        20     40   USA          2023  ...    15           32   \n",
       "3         8     15     UK         2023  ...    18           42   \n",
       "5        25     50     India      2023  ...     9           46   \n",
       "\n",
       "   Text Predicted Sentiment  Text Prediction Confidence  \\\n",
       "0                  positive                    0.936028   \n",
       "1                  negative                    0.976853   \n",
       "2                  positive                    0.923207   \n",
       "3                  positive                    0.975727   \n",
       "5                  positive                    0.916279   \n",
       "\n",
       "  Sentiment Predicted Sentiment  Sentiment Prediction Confidence Num Hashtags  \\\n",
       "0                      positive                         0.987529            2   \n",
       "1                      negative                         0.988335            2   \n",
       "2                      positive                         0.987529            2   \n",
       "3                      positive                         0.987529            2   \n",
       "5                      positive                         0.987529            2   \n",
       "\n",
       "   Final Sentiment                                  Text_lemma  \\\n",
       "0         positive           enjoy a beautiful day at the park   \n",
       "1         negative            traffic be terrible this morning   \n",
       "2         positive              just finish an amazing workout   \n",
       "3         positive  excited about the upcoming weekend getaway   \n",
       "5         positive  feel grateful for the little thing in life   \n",
       "\n",
       "           Hashtags_lemma  \n",
       "0             nature park  \n",
       "1         traffic morning  \n",
       "2         fitness workout  \n",
       "3        travel adventure  \n",
       "5  gratitude positivevibe  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try lemmatization\n",
    "df_model = df.copy()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "def lemmatize_text(s):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    doc = nlp(s.lower())\n",
    "    return \" \".join(tok.lemma_ for tok in doc if not tok.is_punct and not tok.is_space)\n",
    "\n",
    "# Apply to text columns used by TF-IDF\n",
    "df_model[\"Text_lemma\"] = df_model[\"Text\"].apply(lemmatize_text)\n",
    "df_model[\"Hashtags_lemma\"] = df_model[\"Hashtags\"].apply(\n",
    "    lambda tags: lemmatize_text(\" \".join(tags) if isinstance(tags, list) else str(tags))\n",
    ")\n",
    "\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8c3599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text features: ['Text_lemma', 'Hashtags_lemma']\n",
      "Numeric features: ['Retweets', 'Likes', 'Year', 'Month', 'Day', 'Hour', 'Text Length', 'Num Hashtags']\n",
      "Categorical features: ['Platform', 'Country']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.73        42\n",
      "    positive       0.85      1.00      0.92        99\n",
      "\n",
      "    accuracy                           0.87       141\n",
      "   macro avg       0.92      0.79      0.82       141\n",
      "weighted avg       0.89      0.87      0.86       141\n",
      "\n",
      "Confusion matrix:\n",
      " [[24 18]\n",
      " [ 0 99]]\n"
     ]
    }
   ],
   "source": [
    "target_col = \"Final Sentiment\" # column to classify\n",
    "text_col = \"Text_lemma\"\n",
    "\n",
    "# remove columns I don't want as predictors\n",
    "drop_cols = [\n",
    "    target_col,\n",
    "    \"Sentiment\",\n",
    "    \"Text Predicted Sentiment\",\n",
    "    \"Sentiment Predicted Sentiment\",\n",
    "    \"Text Prediction Confidence\",\n",
    "    \"Sentiment Prediction Confidence\",\n",
    "    \"Timestamp\",\n",
    "    \"User\",\n",
    "    \"Text\",\n",
    "    \"Hashtags\"\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", text_transformer, \"Text_lemma\"),\n",
    "        (\"hashtags\", hashtags_transformer, \"Hashtags_lemma\"),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "df_model = df_model.dropna(subset=[target_col, text_col])\n",
    "\n",
    "X = df_model.drop(columns=[c for c in drop_cols if c in df_model.columns], errors=\"ignore\")\n",
    "y = df_model[target_col]\n",
    "\n",
    "# Auto-detect other feature types (excluding text)\n",
    "text_features = [\"Text_lemma\", \"Hashtags_lemma\"]\n",
    "numeric_features = [c for c in X.select_dtypes(include=[np.number]).columns if c not in text_features]\n",
    "categorical_features = [c for c in X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns if c not in text_features]\n",
    "\n",
    "print(\"Text features:\", text_features)\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "\n",
    "# Create model pipeline\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Fit model to training data\n",
    "clf.fit(X_train, y_train)\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly worse with lemmatization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
